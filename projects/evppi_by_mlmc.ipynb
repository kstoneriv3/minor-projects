{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Short implementation of MLMC of EVPPI (Giles, Goda 2017). \n",
    "NOTICE: code is not optimized for performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import packages in advance ###\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "### for code optimization, you might not need this to compute EVPPI ###\n",
    "from numba import jit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimation of Expected Value of Partial Perfect Infomation (EVPPI) has a variety of applications, such as the estimation of the cost effectiveness of medical research, boring survey of oil reservior. However, the estimation of EVPPI had been computationally very costly, since the form of the estimator is the expectation of the nested expectation. In the past it was computed using nested monte carlo with the computational cost of $O(\\varepsilon^{-3})$ to achinve the accuracy of $\\varepsilon$ ($MSE\\leq \\varepsilon^{-2}$). \n",
    "\n",
    "In 2017, Giles and Goda computed this using Multi Level Monte Carlo method and achieved computational complexity of $O(\\varepsilon^{-2})$, which is drastically faster than the conventional nested monte carlo. This notebook is meant to be a short replication of the numerical experiment given in the original paper ([Giles, Goda 2017](https://arxiv.org/abs/1708.05531?context=math))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Theoretical Aspect of MLMC of EVPPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Definition of Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Variable | Explanation |\n",
    "|:-----------|:------------|\n",
    "|$X, Y$| Random variables.|\n",
    "|$d \\in D$|Decision of the given decision set $D$.|\n",
    "|$f_d(X,Y)$|Utility Function of the decision $d$, given $X,Y$.|\n",
    "|$\\displaystyle{ EVI = \\mathbb{E}_{X}[\\max_{d \\in D}{f_d(X)}] - \\max_{d \\in D}{\\mathbb{E}_{X}[f_d(X)]}}$|Expected value of information of $X$.|\n",
    "|$\\displaystyle EVPI = \\mathbb{E}_{X,Y}[\\max_{d \\in D}{f_d(X,Y)}] - \\max_{d \\in D}{\\mathbb{E}_{X,Y}[f_d(X,Y)]}$|Expected value of perfect information of $X,Y$.|\n",
    "|$\\displaystyle EVPPI = \\mathbb{E}_{X}[\\max_{d \\in D}{\\mathbb{E}_{Y \\mid X}[f_d(X,Y)]}] - \\max_{d \\in D}{\\mathbb{E}_{X,Y}[f_d(X,Y)]}$|Expected value of partial perfect information of $X,Y$<br> (expected value of information of $X$ without information of $Y$).|\n",
    "|$\\displaystyle P =\\mathbb{E}_{Y \\mid X}[\\max_{d \\in D}{f_d(X,Y)}] - \\max_{d \\in D}{\\mathbb{E}_{Y \\mid X}[f_d(X,Y)]}$|Inner conditional expectation of $EVPI - EVPPI$, with underlying random variable $X$.<br>Here $P$ satisfies $\\mathbb{E}_{X}[P] = EVPI - EVPPI$.|\n",
    "|$\\displaystyle P_l = \\scriptsize \\overline{\\max_{d \\in D}f_d(X)}^{1:2^{l}}  - \\max_{d \\in D}{ \\overline{f_d(X)}^{1:2^{l}}} $ $ \\displaystyle = \\scriptsize \\frac{1}{2^l}\\sum_{i=1}^{2^l}{\\max_{d \\in D}{f_d(X,Y^{(i)})}} - \\max_{d \\in D}{\\frac{1}{2^l}\\sum_{i=1}^{2^l}{f_d(X,Y^{(i)})}}  $|A consistent estimator of $P$ given $X$ ($\\Leftrightarrow P_l \\xrightarrow{p.} P$ ), with underlying random variable $Y^{(1)}, \\ldots ,Y^{(2^l)}$ and $X$. <br>Note that $\\mathbb{E}_{X}[P_l] \\xrightarrow{p.} \\mathbb{E}_{X}[P] = EVPI - EVPPI$ as $l \\to \\infty$.|\n",
    "|$\\displaystyle Z_l  = \\scriptsize  \\frac{1}{2} \\left[   \\max_{d \\in D}{ \\overline{f_d(X)}^{1:2^{l-1}}} + \\max_{d \\in D}{\\overline{f_d(X)}^{2^{l-1}+1:2^{l}}}  \\right]  - \\max_{d \\in D}{ \\overline{f_d(X)}^{1:2^{l}}} $ $ \\displaystyle = \\scriptsize \\frac{1}{2} \\left[  \\max_{d \\in D}{ \\frac{1}{2^{l-1}}\\sum_{i=1}^{2^{l-1}}f_d(X,Y^{(i)})}  + \\max_{d \\in D}{ \\frac{1}{2^{l-1}}\\sum_{i=1}^{2^{l-1}}f_d(X,Y^{(i)})} \\right] - \\max_{d \\in D}{ \\frac{1}{2^{l}}\\sum_{i=1}^{2^{l}}f_d(X,Y^{(i)})}  $|This is an unbiased estimator of $\\mathbb{E}_{Y \\mid X}[P_l-P_{l-1}] $ given $X$. Here, $ \\mathbb{E}_{Y \\mid X}[P_l-P_{l-1}] $ $= \\mathbb{E}_{Y \\mid X}[P_l] - \\mathbb{E}_{Y \\mid X}[P_{l-1}] $ $= \\mathbb{E}_{Y^{(l,1)}, \\ldots ,Y^{(l,2^l)} \\mid X}[P_l] - \\mathbb{E}_{Y^{(l-1,1)}, \\ldots ,Y^{(l-1,2^{l-1})} \\mid X}[P_{l-1}]$ <br>So, it is clear that $Z_l(X, Y^{(1)}, \\ldots , Y^{(2^l)} )$is an unbiased estimator of $\\mathbb{E}_{X,Y}[P_l-P_{l-1}]$|\n",
    "|$C[Z_l]$|Computational cost of sampling one example of $Z_l$, which is $O( 2^l )$ for fixed $\\lvert D \\rvert$.\n",
    "|$\\displaystyle \\hat{Z}^{(L)} =  \\sum_{l=1}^{L}{\\hat{Z}_l}$<br>Here, $ \\displaystyle  \\hat{Z}_l = \\frac{1}{N_l}\\sum_{n=1}^{N_l}{Z_l(X^{(n, l)}, Y^{(1, n, l)}, Y^{(2, n, l)}, \\ldots , Y^{(2^l, n, l)} )} $, and $ N_1, \\ldots ,N_L$ are determined by MLMC algolithm (Giles 2015) explained in the Section 1.3. |$\\hat{Z}^{(L)}$ is a MLMC estimator of $ \\mathbb{E}_{X}[P]=EVPI - EVPPI$. <br>This is because $\\hat{Z}^{(L)}$ is an unbiased estimator of $\\mathbb{E}_{X,Y}[P_L] = \\sum_{l=1}^{L}{\\mathbb{E}_{X,Y}[P_l-P_{l-1}]}$ since $\\hat{Z}_l$ is an unbiased estimator of $\\mathbb{E}_{X,Y}[P_l-P_{l-1}]$ and $\\mathbb{E}_{X,Y}[P_0]=0$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Mechnism and Algorithm of MLMC Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to take advantage of MLMC when estimating $EVPPI$, we constitute the MLMC estimator of $EVPIâˆ’EVPPI$ instead of the estimator of $EVPPI$ itself. It is because we can reduce the varianvce of MLMC estimator by doing so, and we also can estimate $EVPI$ by  accuracy of $\\varepsilon$ ( or $\\varepsilon_{\\text{total}} / \\sqrt{2}$ ) with computational complexity of $O(\\varepsilon^{-2})$. So we will focus on estimating $EVPI - EVPPI$ with as close cost to $O(\\varepsilon^{-2})$ as possible. \n",
    "\n",
    "\n",
    "Here, the main theorem of the [Giles, Goda 2017](https://arxiv.org/abs/1708.05531?context=math) guarantees that under appropriate ragular conditions regerding the utility function, we can use MLMC algorithm in [Giles 2015](https://www.cambridge.org/core/journals/acta-numerica/article/multilevel-monte-carlo-methods/C5AF9A57ED8FF8FDF08074C1071C5511) to achieve optimal comlexity of $O(\\varepsilon^{-2})$ (otherwise, without that regular condition, complexity is $O(\\varepsilon^{-2}(\\log{\\varepsilon})^2)$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, $\\hat{Z}^{(L)}$ is an unbiased estimator of $\\mathbb{E}_{X,Y}[P_L]$, and $\\mathbb{E}_{X}[P_l] \\xrightarrow{p.} EVPI - EVPPI$. Therefore we can use $\\hat{Z}^{(L)}$ as (biased) estimater of $EVPI - EVPPI$. When estimating $EVPI - EVPPI$ with accuracy of $\\varepsilon$ , we want\n",
    "$$MSE = \\mathbb{E}_{X,Y}\\left[\\{ (EVPI - EVPPI) - \\hat{Z}^{(L)} \\}^2 \\right] = \\sum_{l=1}^{L}{\\frac{\\mathbb{V}_{X,Y}[ Z_l(X,Y) ]}{N_l}} + Bias_{\\hat{Z}^{(L)}} \\leq \\varepsilon^2.$$\n",
    "Here bias-variance decomposition is used in the second equality. And this can be replaced by stronger condition, \n",
    "$$\\sum_{l=1}^{L}{\\frac{\\mathbb{V}_{X,Y}[ Z_l(X,Y) ]}{N_l}} \\leq \\frac{\\varepsilon^2}{2} \\ \\ \\text{and} \\ \\ Bias_{\\hat{Z}^{(L)}} \\leq \\frac{\\varepsilon^2}{2}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the MLMC algorithm, we need to determine both the level $L$ and the number of outer iteration $N_l$ of the estimator $\\hat{Z}_l$ to build estimaer $\\hat{Z}^{(L)}$. In order to do that, (1) we estimate $Bias_{\\hat{Z}^{(L)}}$ for each $L=1,2,3, \\ldots$, and check whether it satisfies $Bias_{\\hat{Z}^{(L)}} \\leq \\varepsilon/2$. (2) Then for the smallest level $L$ that satisfies the condition about the bias term, we compute the optimal $N_1, \\ldots ,N_L$ that achieves $\\sum_{l=1}^{L}{\\frac{\\mathbb{V}_{X,Y}[ Z_l(X,Y) ]}{N_l}} \\leq \\varepsilon^2/2$ with least cost. (3) Finally, the $L$ and the $N_1, \\ldots ,N_L$ can be used to constitute estimator $\\hat{Z}^{(L)}$ whose computational cost is $O(\\varepsilon^{-2})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) Bias estimation and Level Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimating bias term is a bit heuristic, since there are no defacto-standard procedure of the estimation of the bias. However, the main theorem of the [Giles, Goda 2017](https://arxiv.org/abs/1708.05531?context=math) gaurantees the following two inequality under ragular condition.\n",
    "$$\\mathbb{E}[ Z_l ] \\simeq o \\left(2^{-l}\\right)$$\n",
    "So we can expect there exists some $c$ such that $\\mathbb{E}[ Z_l ] \\simeq c2^{-l}$. Then we get \n",
    "$$Bias_{\\hat{Z}^{(L)}} = \\left( \\sum_{l = L+1}^{\\infty}\\mathbb{E}[ P_{l} - P_{l-1} ] \\right)^2= \\left( \\sum_{l = L+1}^{\\infty}\\mathbb{E}[ Z_l ] \\right)^2 \\simeq \\left( \\mathbb{E}[ Z_L ]\\sum_{l' = 1}^{\\infty}2^{-l'}\\right)^2 = \\mathbb{E}[ Z_L ]^2 \\leq \\frac{\\varepsilon^2}{2}.$$\n",
    "Thus we will compute $\\mathbb{E}[ Z_L ]$ for $L=1,2,3,...$, until we find $L$ which satisfies $\\mathbb{E}[ Z_L ] \\leq \\varepsilon / 2$. The estimation of $\\mathbb{E}[ Z_L ]$ will be done using standard monte carlo approximation, \n",
    "$$\\frac{1}{N}\\sum_{n=1}^{N}{Z_L(X^{(n, L)}, Y^{(1, n, L)},  \\ldots , Y^{(2^L, n, L)} )} \\xrightarrow{p.}\\mathbb{E}[ Z_L ].$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Finding Optimal $N_l$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we have fixed the level L, derivation of the optimal $N_1, \\ldots ,N_L$ can be easily done by using Lagrange multiplier method. The \"cost of computing $\\hat{Z}^{(L)}$\" is minimized with constraint of \"variance term\" being $\\varepsilon^2/2$, namely,\n",
    "$$\\min_{N_1, \\ldots , N_L}{\\sum_{l=1}^{L}{N_l C[Z_l]}} \\ \\ s.t. \\ \\ \\sum_{l=1}^{L}{\\frac{\\mathbb{V}[ Z_l ]}{N_l}}=\\frac{\\varepsilon^2}{2}.$$\n",
    "Here, we relaxed the integer condition of $N_1, \\ldots , N_L$. Then we get \n",
    "$$\\hat{N_l} = 2\\varepsilon^{-2} \\sqrt{{\\mathbb{V}[ Z_l ] } \\ /\\ { C[Z_l] }}\\left(  \\sum_{l=0}^{L}{\\sqrt{\\mathbb{V}[ Z_l ]C[Z_l]}} \\right). $$\n",
    "Thus we use $\\scriptsize \\left\\lceil \\hat{N_l} \\right\\rceil $ as the number of inner iteration of the MLMC estimator. By doing so, we get total cost of\n",
    "$$ \\sum_{l=1}^{L}{\\hat{N_l} C[Z_l]} = 2\\varepsilon^{-2} \\left(  \\sum_{l=0}^{L}{\\sqrt{\\mathbb{V}[ Z_l ]C[Z_l]}} \\right)^2.$$\n",
    "This total cost of evaluating $EVPI-EVPPI$ is $O(\\varepsilon^{-2})$, since the squred summation term is proved to be finite. The main theorem of the [Giles, Goda 2017](https://arxiv.org/abs/1708.05531?context=math) proves $\\mathbb{V}[ Z_l ] \\simeq O \\left(2^{-\\frac{3}{2}l}\\right)$ and since $C[Z_l] = O(2^l)$, we can see\n",
    "$$\\sum_{l=0}^{L}{\\sqrt{\\mathbb{V}[ Z_l ]C[Z_l]}} \\leq \\sum_{l=0}^{\\infty}{O(2^{-\\frac{1}{4}l})} < \\infty$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) Computing Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plug in the values we got, and  $\\hat{Z_l}^{(L)}$ is easily computed. <br>Then by subtracting the estimate of $EVPI-EVPPI$ (, which is  $\\hat{Z_l}^{(L)}$,) from $EVPI$, We get the estimate of $EVPPI$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to build function `EVPI_estimator` and `EVPI_minus_EVPPI_estimator` that takes arbitary accuracy `epsilon` as input and returns the estimate with that accuracy. Then we can easily implement the function `EVPPI_estimator` that estimates the $EVPPI$ with accuracy `epsilon_total`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Overview of Functions and Variables in the code\n",
    "Following are the functions implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Function / Variable | Input | Output | Notation | Explanation |\n",
    "|:-------------------:|:------|:-------|:---------|:------------|\n",
    "| `L` | - | Integer (not function) | $L$ | Total levels of the MLMC. |\n",
    "| `epsilon` | - | float (not function) | $\\varepsilon$ | The upper bound of $\\sqrt{MSE}$. |\n",
    "| `D` | - | Tuple of integer (not function) | $D$ | Decision set $D$. |\n",
    "| `f(array_1d_dXY)` |  1 dimentional np.array <br>`np.array([d, X1, X2, ..., Y1, Y2, ...])` | Float | $f_d(X,Y)$ | The utility function to be evaluated. |\n",
    "| `X_sampler(shape)` | Tuple `(N1,N2,...,Nm)`  | m+1 dimentional np.ndarray | $X^{(n_1,\\ldots,n_m)} = (X^{(n_1,\\ldots,n_m)}_1, \\ldots , X^{(n_1,\\ldots,n_m)}_{p_X})$<br>$\\forall n_i = 1,\\ldots,N_i \\ (\\forall i=1,\\ldots,m)$| Sample $X^{(n_1,\\ldots,n_m)} = (X^{(n_1,\\ldots,n_m)}_1, \\ldots , X^{(n_1,\\ldots,n_m)}_{p_X})$. Here, we assume the dimention of the $X^{(i,n,l)}$ to be $p_X$. |\n",
    "| `Y_sampler(shape)` | Tuple `(N1,N2,...,Nm)`  | m+1 dimentional np.ndarray | $Y^{(n_1,\\ldots,n_m)} = (Y^{(n_1,\\ldots,n_m)}_1, \\ldots , Y^{(n_1,\\ldots,n_m)}_{p_Y})$<br>$\\forall n_i = 1,\\ldots,N_i \\ (\\forall i=1,\\ldots,m)$| Sample $Y^{(n_1,\\ldots,n_m)} = (Y^{(n_1,\\ldots,n_m)}_1, \\ldots , Y^{(n_1,\\ldots,n_m)}_{p_Y})$. Here, we assume the dimention of the $Y^{(i,n,l)}$ to be $p_Y$. |\n",
    "| `Z_sampler(l,Nl)` | Integer `l`, `Nl` | 1 dimentional np.ndarray | $Z_l^{(n)}=Z_l(X^{(n, l)}, Y^{(1, n, l)}, Y^{(2, n, l)}, \\ldots , Y^{(2^l, n, l)} )$<br> $\\forall n = 1,\\ldots,N_l$ |Notice that `Zn` is the dictionary of the function `Z_sampler[1]` , ... , `Z_sampler[L]`. <br>Here, `D , f, X_sampler, Y_sampler` is used to build this sampler function. |\n",
    "| `EZ[l]`| - | Float (not function) | $\\mathbb{E}_{X,Y}[Z_l(X,Y)]$ | Notice that `EZ` is the dictionary of the value `EZ[1]` , ... , `EZ[L]`. |\n",
    "| `VZ[l]`| - | Float (not function) | $\\mathbb{V}_{X,Y}[Z_l(X,Y)]$ | Notice that `VZ` is the dictionary of the value `VZ[1]` , ... , `VZ[L]`. |\n",
    "| `CZ[l]` | - |Float (not function) | $C[Z_l]$ | Notice that `Zn` is the dictionary of the value `CZ[1]` , ... , `CZ[L]`. |\n",
    "| `Nhat[l]` | - |Float (not function) | $\\left\\lceil \\hat{N_l} \\right\\rceil $ | Notice that `Nhat` is the dictionary of the value `Nhat[1]` , ... , `Nhat[L]`. |\n",
    "| `EVPI_minus_EVPPI_estimator(epsilon, D , f, X_sampler, Y_sampler)` | Float `epsilon`, tuple `D` and function `f`, `X_sampler`, `Y_sampler` | Dictinary | $\\hat{Z}^{(L)} = \\hat{EVPI-EVPPI}_{\\text{with accuracy } \\varepsilon } $  <br> and so on | - |\n",
    "| `EVPI_estimator(epsilon, D , f, X_sampler, Y_sampler)` | Float `epsilon`, tuple `D` and function `f`, `X_sampler`, `Y_sampler` | Dictionary | $\\displaystyle {\\overline {\\max_{d \\in D}{f_d}} - \\max_{d \\in D}{\\overline{f_d}}}_{\\text{with accuracy } \\varepsilon}$ <br>and so on| - |\n",
    "| `EVPPI_estimator(epsilon, D , f, X_sampler, Y_sampler)` | Float `epsilon`, tuple `D` and function `f`, `X_sampler`, `Y_sampler` | Dictinary | $\\hat{EVPPI}_{\\text{with accuracy } \\varepsilon } $  <br> and so on | Estimate $EVPPI$ with standard MLMC. |\n",
    "|`EVPPI_estimator_StdMC(Nx, Ny, D , f, X_sampler, Y_sampler)`| Integer `Nx`, `Ny`, tuple `D` and function `f`, `X_sampler`, `Y_sampler` | Float | $\\hat{EVPPI}_{\\text{with #sample } N_x, N_y }$ | Estimate $EVPPI$ with standard MC. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Functions for EVPI estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EVPI_estimator_given_N(N, D, f, X_sampler, Y_sampler):\n",
    "    ### d.shape == (|D|, N, 1) \n",
    "    ### X.shape == (|D|,N, dimX), \n",
    "    ### Y.shape == (|D|,N, dimY)\n",
    "    d = np.array(D).reshape((len(D), 1, 1))*np.ones((1, N, 1))\n",
    "    X = X_sampler((1,N))*np.ones((len(D), 1, 1))\n",
    "    Y = Y_sampler((1,N))*np.ones((len(D), 1, 1))\n",
    "\n",
    "    ###  dxy.shape == (|D|,N, 1+dimX+dimY )\n",
    "    dXY = np.concatenate([d,X,Y], axis=2)\n",
    "    \n",
    "    ### f_values.shape ==  (|D|, N)\n",
    "    f_values = np.apply_along_axis(func1d=f, axis=2, arr=dXY)\n",
    "    \n",
    "    meanXY_max = f_values.max(axis=0).mean()\n",
    "    max_meanXY = f_values.mean(axis=1).max()\n",
    "    EVPI = meanXY_max - max_meanXY\n",
    "    \n",
    "    return EVPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def EVPI_estimator(epsilon, D , f, X_sampler, Y_sampler):\n",
    "    ### We use N0 to estimate the error of the stdMC estimator\n",
    "    N0 = 50\n",
    "    Var_N0 = np.array([EVPI_estimator_given_N(N0, D , f, X_sampler, Y_sampler) for i in range(50)]).var()\n",
    "    Var_1 = Var_N0*N0\n",
    "    N = int(Var_1/epsilon**2)+1\n",
    "    EVPI = EVPI_estimator_given_N(N, D , f, X_sampler, Y_sampler)\n",
    "    return {\"N\":N, \"EVPI\":EVPI}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Functions for EVPI - EVPPI estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Z_sampler(l,Nl, D , f, X_sampler, Y_sampler):\n",
    "    Nx = Nl\n",
    "    Ny = 2**l\n",
    "    ### d.shape == (|D|, Nx, Ny, 1) \n",
    "    ### X.shape == (|D|,Nx, Ny, dimX), \n",
    "    ### Y.shape == (|D|,Nx, Ny, dimY)\n",
    "    d = np.array(D).reshape((len(D), 1, 1, 1))*np.ones((1, Nx, Ny, 1))\n",
    "    X = X_sampler((1,Nx,1))*np.ones((len(D),1,Ny,1))\n",
    "    Y = Y_sampler((1,Nx,Ny))*np.ones((len(D), 1, 1,1))\n",
    "\n",
    "    ###  dxy.shape == (|D|,Nx,Ny, 1+dimX+dimY )\n",
    "    dXY = np.concatenate([d,X,Y], axis=3)\n",
    "    \n",
    "    ### f_values.shape ==  (|D|, Nx, Ny)\n",
    "    f_values = np.apply_along_axis(func1d=f, axis=3, arr=dXY)\n",
    "    \n",
    "    ### max_1st_half_meanY.shape = (Nx) = (Nl)\n",
    "    ### max_2nd_half_meanY.shape = (Nx) = (Nl)\n",
    "    ### max_whole_meanY.shape = (Nx) = (Nl)\n",
    "    max_1st_half_meanY = f_values[:,:,:2**(l-1)].mean(axis=2).max(axis=0)\n",
    "    max_2nd_half_meanY = f_values[:,:,2**(l-1):].mean(axis=2).max(axis=0)\n",
    "    max_whole_meanY    = f_values[:,:,:        ].mean(axis=2).max(axis=0)\n",
    "    \n",
    "    return (1/2) * (max_1st_half_meanY + max_2nd_half_meanY) - max_whole_meanY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EVPI_minus_EVPPI_estimator(epsilon, D , f, X_sampler, Y_sampler):\n",
    "    \n",
    "    ### We first estimate the optimal level L for constructing MLMC estimator Zhat = EVPI-EVPPI\n",
    "    Maximum_L = 15 ### other values will be fine\n",
    "    Levels0 = [l+1 for l in range(Maximum_L)]\n",
    "    dumpZ = {}\n",
    "    EZ = {}\n",
    "    VZ = {}\n",
    "    CZ = {}\n",
    "    \n",
    "    for l in Levels0:\n",
    "        dumpZ[l] = Z_sampler(l, 100, D , f, X_sampler, Y_sampler)\n",
    "        EZ[l] = dumpZ[l].mean()\n",
    "        VZ[l] = dumpZ[l].var()\n",
    "        CZ[l] = 2**l\n",
    "        ### Increase the level L, until the bias of Z_hat^(L) seems to get ignorable\n",
    "        if EZ[l]**2 < epsilon**2/2:\n",
    "            break\n",
    "        elif l==Maximum_L:\n",
    "            print(\"Maximum level reached. The result must be inaccurate. Please increase tha Maximum level and retry.\")\n",
    "    L = l\n",
    "    Levels = [l+1 for l in range(L)]\n",
    "\n",
    "    ### Next, we compute Nhat[]\n",
    "    sum_VC_root = sum([(VZ[l]*CZ[l])**(0.5) for l in Levels])\n",
    "    Nhat = {l: int(2*epsilon**(-2)*(VZ[l]/CZ[l])**0.5*sum_VC_root)+1 for l in Levels}\n",
    "\n",
    "    ### Finally, we compute Zhat = EVPI-EVPPI\n",
    "    EVPI_minus_EVPPI = sum([Z_sampler(l, Nhat[l], D , f, X_sampler, Y_sampler).mean() for l in Levels])\n",
    "    result = {\"EVPI_minus_EVPPI\":EVPI_minus_EVPPI, \"Nhat\":Nhat, \"EZ\":EZ, \"CZ\":CZ, \"VZ\":VZ, \"Total_C\":sum([CZ[l]*Nhat[l] for l in Levels]) }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 MLMC estimation of EVPPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to estimate EVPPI with total MSE of estimator being less than $\\varepsilon_{\\text{total}}^2$, we estimate $EVPI$ and $EVPI-EVPPI$ with accuracy of $\\varepsilon_{\\text{total}} / \\sqrt2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def EVPPI_estimator(epsilon_total, D , f, X_sampler, Y_sampler):\n",
    "    result_EVPI =  EVPI_estimator(epsilon_total/2**0.5, D , f, X_sampler, Y_sampler)\n",
    "    result_EVPI_minus_EVPPI = EVPI_minus_EVPPI_estimator(epsilon_total/2**0.5, D , f, X_sampler, Y_sampler)\n",
    "    \n",
    "    result = result_EVPI_minus_EVPPI\n",
    "    result[\"Total_C\"] = result_EVPI_minus_EVPPI[\"Total_C\"] + result_EVPI[\"N\"]\n",
    "    \n",
    "    EVPI = result_EVPI[\"EVPI\"]\n",
    "    EVPI_minus_EVPPI = result_EVPI_minus_EVPPI[\"EVPI_minus_EVPPI\"]\n",
    "    EVPPI = EVPI - EVPI_minus_EVPPI\n",
    "    result[\"EVPPI\"] = EVPPI\n",
    "    \n",
    "    result.pop(\"EVPI_minus_EVPPI\")\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Standard Monte Carlo estimation of EVPPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EVPPI_estimator_StdMC(Nx, Ny, D , f, X_sampler, Y_sampler):\n",
    "    ### create list of 1 dimentional np.array to be fed in np.vectorize ###\n",
    "    ### d.shape == (|D|, Nx, Ny, 1) \n",
    "    ### X.shape == (|D|,Nx, Ny, dimX), \n",
    "    ### Y.shape == (|D|,Nx, Ny, dimY)\n",
    "    d = np.array(D).reshape((len(D), 1, 1, 1))*np.ones((1, Nx, Ny, 1))\n",
    "    X = X_sampler((1,Nx,1))*np.ones((len(D),1,Ny,1))\n",
    "    Y = Y_sampler((1,Nx,Ny))*np.ones((len(D), 1, 1,1))\n",
    "\n",
    "    ###  dxy.shape == (|D|,Nx,Ny, 1+dimX+dimY )\n",
    "    dXY = np.concatenate([d,X,Y], axis=3)\n",
    "    \n",
    "    ### f_values.shape ==  (|D|, Nx, Ny)\n",
    "    f_values = np.apply_along_axis(func1d=f, axis=3, arr=dXY)\n",
    "\n",
    "    meanX_max_meanY = f_values.mean(axis=2).max(axis=0).mean()\n",
    "    max_meanX_meanY = f_values.mean(axis=(1,2)).max()\n",
    "    EVPPI_stdMC = meanX_max_meanY - max_meanX_meanY\n",
    "    return EVPPI_stdMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Numerical Experiment\n",
    "\n",
    "### 3.1 Condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the first test case in the [Giles, Goda 2017](https://arxiv.org/abs/1708.05531?context=math), where $D=\\{0,1\\}$ and $X, Y \\sim N(0,1)$, $f_0(X,Y) = 0$, $ f_1(X,Y)=X+Y$.<br>\n",
    "Since we can analyticaly see that $$EVPPI = \\int_{0}^{\\infty}x \\frac{1}{\\sqrt{2\\pi}}\\exp{\\left(\\frac{1}{2}x^2\\right)}dx = \\frac{1}{\\sqrt{2\\pi}}$$,\n",
    "we know that $EVPPI = 0.39894228...$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initialize Constants and Utility Function ###\n",
    "### d should be integer\n",
    "D = (0,1)\n",
    "epsilon_total = 0.001\n",
    "\n",
    "def f(array_1d_dXY):\n",
    "    d = array_1d_dXY[0]\n",
    "    X1 = array_1d_dXY[1]\n",
    "    Y1 = array_1d_dXY[2]\n",
    "    return d*(X1+Y1)\n",
    "\n",
    "### Initialize smpler of X and Y ###\n",
    "### X2 and Y2 are not used this time.\n",
    "def X_sampler(shape):\n",
    "    X1 = np.random.randn(*shape)\n",
    "    shape_index = tuple(i+1 for i in range(len(shape)))\n",
    "    return np.array([X1]).transpose(*shape_index,0)\n",
    "    \n",
    "def Y_sampler(shape):\n",
    "    Y1 = np.random.randn(*shape)\n",
    "    shape_index = tuple(i+1 for i in range(len(shape)))\n",
    "    return np.array([Y1]).transpose(*shape_index,0)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Computation and Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This might take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 42.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = EVPPI_estimator(epsilon_total, D , f, X_sampler, Y_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4002945665860228"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EVPPI = result[\"EVPPI\"]\n",
    "EVPPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Standard Monte Carlo (for sanity check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Nx = 1000\n",
    "Ny = 1000\n",
    "EVPPI_StdMC = EVPPI_estimator_StdMC(Nx, Ny, D , f, X_sampler, Y_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37026396170216747"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EVPPI_StdMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our MLMC estimate is in good align with standard monte carlo result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Computational Cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the relation between the \"accuracy\" and the \"total cost\".<br>\n",
    "The line graph below shows that the total cost are $O({\\varepsilon_{\\text{total}}}^{-2})$, for accuracy $\\varepsilon_{\\text{total}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### This might take some minutes. ###\n",
    "Accuracy_list = [2**(-i-3) for i in range(8)]\n",
    "Cost_list = [EVPPI_estimator(epsilon_total, D , f, X_sampler, Y_sampler)[\"Total_C\"] for epsilon_total in Accuracy_list]\n",
    "Cost_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfwAAAEdCAYAAADpStU0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc6b03b6828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "% matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.xlabel(\"Accuracy\")\n",
    "plt.ylabel(\"Total Computational Cost\")\n",
    "plt.title(\"Computational cost vs Accuracy\")\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.plot(Accuracy_list , Cost_list)\n",
    "plt.plot([1e-0,1e-4],[1e-0,1e+8],c=\"gray\")\n",
    "plt.legend([\"MLMC_Cost vs Accuracy\",\"Cost = Accuracy^(-2)\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Appendix (More Complex Utility Function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Use of Customized Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The EVPPI for more complex utility functions can be computed like following.<br>\n",
    "Here, we set $D=\\{0,1\\}$ and $X_1,...,X_4, Y_1,...,Y_4 \\sim N(0,1)$, $f_0(X,Y) = 0$, $f_1 = \\sum X_i + \\sum Y_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since $\\sum X_i, \\sum Y_i \\sim N(0,2)$, we can think that we have just scaled up the first test case by 2 times this time. <br>\n",
    "So it is natural that the result we get this time is just about 2 times larger than the result of first case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initialize Constants and Utility Function ###\n",
    "### d should be integer\n",
    "D2 = (0,1)\n",
    "epsilon_total2 = 0.005\n",
    "\n",
    "def f2(array_1d_dXY):\n",
    "    d = array_1d_dXY[0]\n",
    "    X1 = array_1d_dXY[1]\n",
    "    X2 = array_1d_dXY[2]\n",
    "    X3 = array_1d_dXY[3]\n",
    "    X4 = array_1d_dXY[4]\n",
    "    Y1 = array_1d_dXY[5]\n",
    "    Y2 = array_1d_dXY[6]\n",
    "    Y3 = array_1d_dXY[7]\n",
    "    Y4 = array_1d_dXY[8]\n",
    "    return d*(X1+X2+X3+X4+Y1+Y2+Y3+Y4)\n",
    "\n",
    "### Initialize smpler of X and Y ###\n",
    "### X2 and Y2 are not used this time.\n",
    "def X_sampler2(shape):\n",
    "    X1 = np.random.randn(*shape)\n",
    "    X2 = np.random.randn(*shape)\n",
    "    X3 = np.random.randn(*shape)\n",
    "    X4 = np.random.randn(*shape)\n",
    "    shape_index = tuple(i+1 for i in range(len(shape)))\n",
    "    return np.array([X1,X2,X3,X4]).transpose(*shape_index,0)\n",
    "    \n",
    "def Y_sampler2(shape):\n",
    "    Y1 = np.random.randn(*shape)\n",
    "    Y2 = np.random.randn(*shape)\n",
    "    Y3 = np.random.randn(*shape)\n",
    "    Y4 = np.random.randn(*shape)\n",
    "    shape_index = tuple(i+1 for i in range(len(shape)))\n",
    "    return np.array([Y1,Y2,Y3,Y4]).transpose(*shape_index,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result2 = EVPPI_estimator(epsilon_total2, D2 , f2, X_sampler2, Y_sampler2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79807143239268608"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EVPPI2 = result2[\"EVPPI\"]\n",
    "EVPPI2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check if the result of standard monte carlo computation of EVPPI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 12.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Nx2 = 1000\n",
    "Ny2 = 1000\n",
    "EVPPI_StdMC2 = EVPPI_estimator_StdMC(Nx2, Ny2, D2, f2, X_sampler2, Y_sampler2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79616383628199705"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EVPPI_StdMC2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Optimization of your Customized Function (for speeding up)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use larger function (e.g. the one that includes 'for loop'),  that can be bottleneck of the computation. <br>\n",
    "So if that is the case for you, we should speed up that function using packages such as 'Cython' or 'Numba'. \n",
    "Below is the example of use of 'Numba'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(\"f8(f8[:])\")\n",
    "def f2_100_jit(array_1d_dXY):\n",
    "    d = array_1d_dXY[0]\n",
    "    X1 = array_1d_dXY[1]\n",
    "    X2 = array_1d_dXY[2]\n",
    "    X3 = array_1d_dXY[3]\n",
    "    X4 = array_1d_dXY[4]\n",
    "    Y1 = array_1d_dXY[5]\n",
    "    Y2 = array_1d_dXY[6]\n",
    "    Y3 = array_1d_dXY[7]\n",
    "    Y4 = array_1d_dXY[8]\n",
    "    Sum = 0\n",
    "    for i in range(100):\n",
    "        Sum = Sum + d*(X1+X2+X3+X4+Y1+Y2+Y3+Y4)*(1/100)\n",
    "    return Sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you implement the function above without 'Numba', it would run 10~20 times slower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def f2_100(array_1d_dXY):\n",
    "    d = array_1d_dXY[0]\n",
    "    X1 = array_1d_dXY[1]\n",
    "    X2 = array_1d_dXY[2]\n",
    "    X3 = array_1d_dXY[3]\n",
    "    X4 = array_1d_dXY[4]\n",
    "    Y1 = array_1d_dXY[5]\n",
    "    Y2 = array_1d_dXY[6]\n",
    "    Y3 = array_1d_dXY[7]\n",
    "    Y4 = array_1d_dXY[8]\n",
    "    Sum = 0\n",
    "    for i in range(100):\n",
    "        Sum = Sum + d*(X1+X2+X3+X4+Y1+Y2+Y3+Y4)*(1/100)\n",
    "    return Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 128 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "EVPPI_estimator(0.05, D2 , f2_100_jit, X_sampler2, Y_sampler2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 2.13 s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "EVPPI_estimator(0.05, D2 , f2_100, X_sampler2, Y_sampler2)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
